{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###### when running the script, it would take few days or more than a week to complete the process of analyzing the text data using Perspective API. The script is designed to handle the API traffic limits and timeouts, but it may still take a long time to process all the data. The script can be stopped and resumed at any time, and it will continue from where it left off. The script will save intermediate results after processing each part of the dataset, so you can check the results and resume the script if needed. The script will also save the final results in a separate file for each dataset. ",
   "id": "339ee58c1753b332"
  },
  {
   "cell_type": "code",
   "id": "4a384230-c4f0-4c7c-8ec9-697198b7b192",
   "metadata": {},
   "source": [
    "# loaded necessary libraries and modules for the script to run successfully\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import emoji\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from googleapiclient import discovery"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aceebfd2-94b6-4219-9d06-6be1eee117e3",
   "metadata": {},
   "source": [
    "# file paths of each needed dataset\n",
    "female_comments_path = \"/home/haters/Downloads/loaded_data/Combined_data_29Apr/combined_female_comments.csv\"\n",
    "male_comments_path = \"/home/haters/Downloads/loaded_data/Combined_data_29Apr/combined_male_comments.csv\"\n",
    "female_submissions_path = \"/home/haters/Downloads/loaded_data/Combined_data_29Apr/combined_female_submissions.csv\"\n",
    "male_submissions_path = \"/home/haters/Downloads/loaded_data/Combined_data_29Apr/combined_male_submissions.csv\"\n",
    "\n",
    "# load dataset from the file paths\n",
    "female_com_df = pd.read_csv(female_comments_path)\n",
    "male_com_df = pd.read_csv(male_comments_path)\n",
    "female_sub_df = pd.read_csv(female_submissions_path)\n",
    "male_sub_df = pd.read_csv(male_submissions_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10a20fa7-5ea2-49cd-a537-e6543e21dc9e",
   "metadata": {},
   "source": [
    "# initial a list of the datasets to be processed\n",
    "dfs = [female_com_df, male_com_df, female_sub_df, male_sub_df]\n",
    "\n",
    "# drop 'temp_id' column if it exists\n",
    "for df in dfs:\n",
    "    if 'temp_id' in df.columns:\n",
    "        df.drop(columns=['temp_id'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3facf23b-aca0-4c43-b8de-cd19a3391c9d",
   "metadata": {},
   "source": [
    "# split DataFrame into n parts\n",
    "def split_dataframe(df, n=3):\n",
    "    return [df.iloc[i::n, :].reset_index(drop=True) for i in range(n)]\n",
    "\n",
    "# split DataFrame into 2 parts, then each of those parts into 3 smaller parts\n",
    "def split_and_subsplit_dataframe(df, split_n=2, subsplit_n=3):\n",
    "    main_parts = split_dataframe(df, split_n)\n",
    "    sub_parts = []\n",
    "    for part in main_parts:\n",
    "        sub_parts.append(split_dataframe(part, subsplit_n))\n",
    "    return sub_parts\n",
    "\n",
    "female_sub_parts = split_dataframe(female_sub_df)\n",
    "male_com_parts = split_dataframe(male_com_df)\n",
    "male_sub_parts = split_dataframe(male_sub_df)\n",
    "female_com_parts = split_and_subsplit_dataframe(female_com_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Toxicity and Sexually Explicit Detection using Perspective API (Submissions dataset)",
   "id": "b266dd9a634d329c"
  },
  {
   "cell_type": "code",
   "id": "7dedb544-29e2-402a-adac-e48ff063e9e2",
   "metadata": {},
   "source": [
    "# list of API keys to use for Perspective API (get your own keys at https://console.developers.google.com/)\n",
    "API_KEYS = [\n",
    "    'AIzaSyA_uZndSn69dCshlHBt01IZRmmL6GV00eM',\n",
    "    'AIzaSyCOjCPE66GcfVJHyXkUF72P1ibU6XKz6e4',\n",
    "    'AIzaSyAU9TrCiUwaSbDkF1CSR9cpKJ-4FJAy-4s', \n",
    "    'AIzaSyDPieGPiGBulfG7xcbRSIaj-vG6o_sq0h0', \n",
    "    'AIzaSyBHTLT8p7Rp5dkIpQ3zZwwo7NUhc8-DkmY', \n",
    "    'AIzaSyC_dlgL-RP6T5dsHe_qSjPQbqtrH_0R6Xc'\n",
    "]\n",
    "\n",
    "# create a list of clients using the API keys\n",
    "clients = [\n",
    "    discovery.build(\n",
    "        \"commentanalyzer\",\n",
    "        \"v1alpha1\",\n",
    "        developerKey=api_key,\n",
    "        discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "        static_discovery=False,\n",
    "    ) for api_key in API_KEYS\n",
    "]\n",
    "\n",
    "# basic text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    text = emoji.demojize(text)  # Convert emojis to text\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "# function to analyze text using Perspective API with timeout handling\n",
    "def get_toxicity_and_sexually_explicit_scores(client, text, sleep_time=1, retry_limit=3):\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "    analyze_request = {\n",
    "        'comment': {'text': preprocessed_text},\n",
    "        'requestedAttributes': {'TOXICITY': {}, 'SEXUALLY_EXPLICIT': {}}\n",
    "    }\n",
    "    retries = 0\n",
    "    while retries < retry_limit:\n",
    "        try:\n",
    "            response = client.comments().analyze(body=analyze_request).execute()\n",
    "            toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "            sexually_explicit_score = response['attributeScores']['SEXUALLY_EXPLICIT']['summaryScore']['value']\n",
    "            return toxicity_score, sexually_explicit_score\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing text: {e}. Retrying ({retries + 1}/{retry_limit})...\")\n",
    "            retries += 1\n",
    "            time.sleep(sleep_time)\n",
    "    print(f\"Skipping text after {retry_limit} retries: {preprocessed_text[:30]}...\")  # Log the problematic text\n",
    "    return None, None\n",
    "\n",
    "# function to process DataFrame with multiple API keys\n",
    "def process_dataframe(df, clients):\n",
    "    toxicity_scores = []\n",
    "    sexually_explicit_scores = []\n",
    "    client_count = len(clients)\n",
    "    for i, text in enumerate(tqdm(df['body'], desc=\"Processing rows\")):\n",
    "        client = clients[i % client_count]  # Rotate clients\n",
    "        toxicity_score, sexually_explicit_score = get_toxicity_and_sexually_explicit_scores(client, text)\n",
    "        toxicity_scores.append(toxicity_score)\n",
    "        sexually_explicit_scores.append(sexually_explicit_score)\n",
    "        if (i + 1) % (50 * client_count) == 0:  # Adjust the batch size as needed\n",
    "            time.sleep(60)  # Sleep for 60 seconds after every batch\n",
    "    df['toxicity_score'] = toxicity_scores\n",
    "    df['sexually_explicit_score'] = sexually_explicit_scores\n",
    "    return df\n",
    "\n",
    "# ensure the output directory exists\n",
    "output_dir = \"/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# process each part and save intermediate results\n",
    "def process_and_save_parts(parts, filename_prefix, clients):\n",
    "    processed_parts = []\n",
    "    for i, part in enumerate(parts):\n",
    "        processed_part = process_dataframe(part, clients)\n",
    "        processed_part.to_csv(f\"{output_dir}{filename_prefix}_part_{i+1}.csv\", index=False)\n",
    "        processed_parts.append(processed_part)\n",
    "    return processed_parts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# process and save the parts of toxic and sexually explicit scores for female submissions dataset\n",
    "female_sub_preprocessed_parts = process_and_save_parts(female_sub_parts, 'female_submissions_outcome', clients)\n",
    "final_df = pd.concat(female_sub_preprocessed_parts).reset_index(drop=True)\n",
    "final_df.to_csv('home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/female_submissions_outcome.csv', index=False)"
   ],
   "id": "e8adc2c2edb5d9b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# process and save the parts of toxic and sexually explicit scores for male submissions dataset\n",
    "male_sub_preprocessed_parts = process_and_save_parts(male_sub_parts, 'male_submissions_outcome', clients)\n",
    "final_df = pd.concat(male_sub_preprocessed_parts).reset_index(drop=True)\n",
    "final_df.to_csv('home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/male_submissions_outcome.csv', index=False)"
   ],
   "id": "3707066b9ce10477",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Toxicity and Sexually Explicit Detection using Perspective API (Comments dataset)",
   "id": "a23962edce951e91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the function for process and save the parts of toxic and sexually explicit scores for male comments dataset\n",
    "def process_and_save_parts(parts, filename_prefix, clients, start_part=1):\n",
    "    for i, part in enumerate(parts, start=1):\n",
    "        if i >= start_part:\n",
    "            processed_part = process_dataframe(part, clients)\n",
    "            processed_part.to_csv(f\"{output_dir}{filename_prefix}_part_{i}.csv\", index=False)\n",
    "            print(f\"Processed and saved {filename_prefix}_part_{i}.csv\")"
   ],
   "id": "be25d3dacdae45ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "process_and_save_parts(male_com_parts, 'male_com', clients, start_part=1)",
   "id": "745f06bb978e42f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# define the function for process and save the parts of toxic and sexually explicit for female comments dataset\n",
    "def process_and_save_parts(parts, filename_prefix, clients, main_part=1, start_subpart=3):\n",
    "    for i, part in enumerate(parts[main_part - 1], start=1):\n",
    "        if i >= start_subpart:\n",
    "            processed_part = process_dataframe(part, clients)\n",
    "            processed_part.to_csv(f\"{output_dir}{filename_prefix}_mainpart_{main_part}_subpart_{i}.csv\", index=False)\n",
    "            print(f\"Processed and saved {filename_prefix}_mainpart_{main_part}_subpart_{i}.csv\")"
   ],
   "id": "e559554163c9c51b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cdc581ef-7897-4ea0-b650-64a90a0b20ca",
   "metadata": {},
   "source": "process_and_save_parts(female_com_parts, 'female_com_parts', clients, main_part=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "process_and_save_parts(female_com_parts, 'female_com_parts', clients, main_part=2)",
   "id": "4e9c7b03d515e88b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Process Missing Parts (that failed to process in earlier runs due to API traffic limits)",
   "id": "25708b3363ba6480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def combine_csv_files(gender='female', data_type='comments', n=3):    \n",
    "    base_path = f\"/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/\"\n",
    "    file_pattern = f\"{base_path}{gender}_{data_type}_outcome_part_{{}}.csv\"\n",
    "    dataframes = [pd.read_csv(file_pattern.format(i+1)) for i in range(n)]\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def combine_csv_files_for_feCom(gender='female', data_type='comments'):\n",
    "    base_path = f\"/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/\"\n",
    "    file_pattern = f\"{base_path}{gender}_com_parts_mainpart_*_subpart_*.csv\"\n",
    "    # get a list of all files matching the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    # read and concatenate all matching files\n",
    "    dataframes = [pd.read_csv(file) for file in file_list]\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df"
   ],
   "id": "11bca2a69ebfd865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "combined_female_submissions = combine_csv_files(gender='female', data_type='submissions')\n",
    "combined_male_submissions = combine_csv_files(gender='male', data_type='submissions')\n",
    "combined_male_comments = combine_csv_files(gender='male', data_type='comments')\n",
    "combined_female_comments = combine_csv_files_for_feCom(gender='female', data_type='comments')\n",
    "duplicate_rows_specific = combined_female_comments[combined_female_comments.duplicated(subset=['retrieved_on', 'body', 'link_id', 'artist'])]"
   ],
   "id": "66786887b417b2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Checked Missing Rows",
   "id": "cdda342843a3fed4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "columns_to_check = ['toxicity_score', 'sexually_explicit_score']\n",
    "\n",
    "def filter_missing_scores(df, columns):\n",
    "    missing_scores_df = df[df[columns].isna().any(axis=1)]\n",
    "    return missing_scores_df\n",
    "\n",
    "def filter_no_urls(df, column_name):\n",
    "    no_urls_df = df[~df[column_name].str.contains(r'http\\S+', regex=True, na=False)]\n",
    "    return no_urls_df\n",
    "\n",
    "def filter_not_only_emojis(df, column_name):\n",
    "    emoji_pattern = re.compile(\n",
    "        '['\n",
    "        u'\\U0001F600-\\U0001F64F'  # emoticons\n",
    "        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n",
    "        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n",
    "        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n",
    "        u'\\U00002702-\\U000027B0'  # dingbats\n",
    "        u'\\U000024C2-\\U0001F251'  # enclosed characters\n",
    "        ']+', flags=re.UNICODE)\n",
    "    \n",
    "    not_only_emojis_df = df[~df[column_name].apply(lambda x: bool(emoji_pattern.fullmatch(x)) if isinstance(x, str) else False)]\n",
    "    return not_only_emojis_df"
   ],
   "id": "e0e43afdb9e13e72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "missing_scores_female_sub_df = filter_missing_scores(combined_female_submissions, columns_to_check)\n",
    "filtered_female_sub_df = filter_no_urls(missing_scores_female_sub_df, 'selftext')\n",
    "\n",
    "missing_scores_male_sub_df = filter_missing_scores(combined_male_submissions, columns_to_check)\n",
    "filtered_male_sub_df = filter_no_urls(missing_scores_male_sub_df, 'selftext')"
   ],
   "id": "38984e34bc4f1898"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "missing_scores_male_com_df = filter_missing_scores(combined_male_comments, columns_to_check)\n",
    "filtered_male_com_df = filter_no_urls(missing_scores_male_com_df, 'body')\n",
    "\n",
    "missing_scores_female_com_df = filter_missing_scores(combined_female_comments, columns_to_check)\n",
    "filtered_female_com_df = filter_no_urls(missing_scores_female_com_df, 'body')\n",
    "filtered_female_com_df = filter_not_only_emojis(filtered_female_com_df, 'body')"
   ],
   "id": "517964f69ef6c3e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "combined_female_comments.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/female_comments_outcome_final_24.csv', index=False)",
   "id": "ebd60454bc721a3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Apply Perspective API to Missing Rows (that failed to process in earlier runs)",
   "id": "60b0f173e9d075c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "female_sub_missing = process_dataframe(filtered_female_sub_df, clients)\n",
    "missing_scores_female_sub_df = filter_missing_scores(female_sub_missing, columns_to_check)\n",
    "filtered_female_sub_df = filter_no_urls(missing_scores_female_sub_df, 'selftext')"
   ],
   "id": "cd5183c4d97add0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace the missing scores in the original DataFrame\n",
    "combined_female_submissions.loc[combined_female_submissions[columns_to_check].isna().any(axis=1), columns_to_check] = \\\n",
    "    female_sub_missing[columns_to_check]"
   ],
   "id": "ed17e7f6627e14fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the final dataset\n",
    "missing_scores_female_sub_df = filter_missing_scores(combined_female_submissions, columns_to_check)\n",
    "filtered_female_sub_df = filter_no_urls(missing_scores_female_sub_df, 'selftext')"
   ],
   "id": "f6442ea638e960ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save the dataframe\n",
    "combined_female_submissions.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/female_submissions_outcome_final.csv', index=False)"
   ],
   "id": "9c3507ee33a9232f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "male_sub_missing = process_dataframe(filtered_male_sub_df, clients)\n",
    "\n",
    "combined_male_submissions.loc[combined_male_submissions[columns_to_check].isna().any(axis=1), columns_to_check] = \\\n",
    "    male_sub_missing[columns_to_check]"
   ],
   "id": "3c0eb2056ff05369"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace the missing scores in the original DataFrame\n",
    "combined_male_submissions.loc[combined_male_submissions[columns_to_check].isna().any(axis=1), columns_to_check] = \\\n",
    "    male_sub_missing[columns_to_check]"
   ],
   "id": "8f8f694a565b3f82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the missing data again \n",
    "missing_scores_male_sub_df = filter_missing_scores(male_sub_missing, columns_to_check)\n",
    "filtered_male_sub_df = filter_no_urls(missing_scores_male_sub_df, 'selftext')"
   ],
   "id": "8997dbc646874353"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the final dataset\n",
    "missing_scores_male_sub_df = filter_missing_scores(combined_male_submissions, columns_to_check)\n",
    "filtered_male_sub_df = filter_no_urls(missing_scores_male_sub_df, 'selftext')"
   ],
   "id": "cae8a979349a9a6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save the dataframe\n",
    "combined_male_submissions.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/male_submissions_outcome_final.csv', index=False)"
   ],
   "id": "2fe1bac71ce52361"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "male_com_missing = process_dataframe(filtered_male_com_df, clients)\n",
    "combined_male_comments.loc[combined_male_comments[columns_to_check].isna().any(axis=1), columns_to_check] = \\\n",
    "    male_com_missing[columns_to_check]"
   ],
   "id": "c10a37ad394b2b6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace the missing data \n",
    "combined_male_comments.loc[combined_male_comments[columns_to_check].isna().any(axis=1), columns_to_check] = \\\n",
    "    male_com_missing[columns_to_check]"
   ],
   "id": "50e71741e6ad2644"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the missing data again \n",
    "missing_scores_male_com_df = filter_missing_scores(male_com_missing, columns_to_check)\n",
    "filtered_male_com_df = filter_no_urls(missing_scores_male_com_df, 'body')"
   ],
   "id": "786cda3b5ccb477a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# save the dataframe\n",
    "combined_male_comments.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/male_comments_outcome_final.csv', index=False)"
   ],
   "id": "4837234bf858cb87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## for female comments data replace the missing data \n",
    "female_com_missing = process_dataframe(filtered_female_com_df, clients)\n",
    "combined_female_comments.loc[combined_female_comments[columns_to_check].isna().any(axis=1), columns_to_check] = female_com_missing[columns_to_check]\n",
    "combined_female_comments.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/female_comments_outcome_final.csv', index=False)"
   ],
   "id": "36ff0a355ca8adb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# check the missing data again \n",
    "missing_scores_female_com_df = filter_missing_scores(female_com_missing, columns_to_check)\n",
    "filtered_female_com_df = filter_no_urls(missing_scores_female_com_df, 'body')"
   ],
   "id": "e67f3847b33e3a98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the dataframe\n",
    "combined_female_comments.to_csv('/home/haters/Downloads/Toxicity_Detection/output_perspective/output_score/female_comments_outcome_final.csv', index=False)"
   ],
   "id": "9a9ff82c1cf61655"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
